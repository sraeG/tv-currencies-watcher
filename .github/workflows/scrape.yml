name: scrape-tradingview-currencies-recent
on:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch: {}
concurrency:
  group: scrape-tradingview-currencies-recent
  cancel-in-progress: true
jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Sanity-check DATABASE_URL shape (no password)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python - << 'PY'
          import os, urllib.parse
          url = os.environ["DATABASE_URL"].strip()
          # Basic validation
          assert url.startswith(("postgres://","postgresql://")), f"Bad scheme: {url[:20]}"
          print("Has sslmode=require?", "sslmode=require" in url)
          # Scrub password then print host:port/db
          without_scheme = url.split("://",1)[1]
          creds_and_rest = without_scheme.split("@",1)
          rest = creds_and_rest[1] if len(creds_and_rest)==2 else without_scheme
          host_port_db = rest.split("?",1)[0]
          print("Host/Port/DB:", host_port_db)
          PY

      - name: Run scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          JITTER_LOW: "10"
          JITTER_HIGH: "20"
          DEBUG_DB_URL: "0"   # <- optional, for one run
          DEBUG_HTML: "0"
        run: |
          python cloud/scraper.py
          

